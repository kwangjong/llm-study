{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG\n",
    "\n",
    "Retrieval Augmented Generation (RAG)\n",
    "- Retrieval: retrieve data from data store (vector db)\n",
    "- Augmented: augment retrieved data to llm\n",
    "- Generation: generate response \n",
    "\n",
    "데이터를 잘 가져와서 LLM이 답변을 할수 있도록 하는 역할\n",
    "- 데이터를 잘 저장해야지 잘 가져옴\n",
    "- 잘 전달하려면 프롬프트를 잘 활용해야됨\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector DB\n",
    "\n",
    "사용자의 질문과 관련있는 데이터\n",
    "- Vector를 사용해 관련성 파악 (단어 또는 문장의 유사도를 파악해서 관련성 측정)\n",
    "- Embedding 모델을 활용해 생성된 vector를 저장 \n",
    "  - metadata도 같이 저장\n",
    "  - chucking을 통해 문서를 나눠서 저장\n",
    "\n",
    "1. 사용자의 질문과 관련있는 문서를 가져오는것 - Retrieval\n",
    "2. 가저온 문서를 prompt를 통해 LLM에 제공 - Augmented\n",
    "3. LLM은 prompt를 활용해서 답변 생성 - Generation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
